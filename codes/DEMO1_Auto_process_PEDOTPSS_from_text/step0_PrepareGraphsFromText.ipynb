{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In DEMO1, text-based preparing procedures of PEDOT-PSS will be converted to graphs and treated by a graph neural net to predict electric conductivity\n",
    "- step0: text was converted to graphs by natural language parser\n",
    "- step1: graph databases are cleaned and formatted\n",
    "- step2: graph databases will be converted to adjacency matrixes and node vectors for ML\n",
    "- step3: ML is done with a graph neural net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This script will prepare graphs from text of PEDOT-PSS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import re\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "import numpy as np\n",
    "import joblib\n",
    "import stanfordnlp\n",
    "\n",
    "os.chdir(\"praparingGraphs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Firstly, load text \n",
    "- load preparation procedure of PEDOT-PSS films"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"20200227pedotPSS.txt\"\n",
    "\n",
    "#load processing data\n",
    "with open(path) as f:\n",
    "    txt = f.read()\n",
    "txt=txt.replace(\"\\n\",\"\")\n",
    "\n",
    "#preprocessing some words (this was temporality done because nlp parser splits two nodes from the phrases, wghich is not appreciated)\n",
    "#TODO: this first aid is far from elegant\n",
    "txt=txt.replace(\"electric conductivity\",\"electricconductivity\")\n",
    "txt=txt.replace(\"S/cm\",\"Scm\")\n",
    "txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculate z-score of numbers\n",
    "- calculations were done for each unit (S/cm, etc)\n",
    "- conductivity was converted in a log scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "rePhrase='[ |\\(]\\d+(?:\\.\\d+)? \\w*'\n",
    "\n",
    "#extract the followng phrases: \" number unit\" or \"(number unit\"\n",
    "numPlusUnit=re.findall(rePhrase, txt) \n",
    "numPlusUnit=[i[1:] for i in numPlusUnit]\n",
    "\n",
    "df=pd.DataFrame(numPlusUnit)\n",
    "df=df[0].str.split(\" \",expand=True)\n",
    "\n",
    "unitList=list(set(df[1]))\n",
    "\n",
    "#fit\n",
    "scalingDict={}\n",
    "for unit in unitList:\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    valList=df[df[1]==unit][0].values\n",
    "    valList=np.array([float(i) for i in valList])\n",
    "    \n",
    "    \n",
    "    if unit==\"Scm\":\n",
    "        valList=np.log10(valList)\n",
    "        \n",
    "    scalingDict[unit]=scaler.fit(valList.reshape(-1,1))\n",
    "    \n",
    "#make dict of scaling\n",
    "joblib.dump(scalingDict,\"scalingDictForPEDOTPSS.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforming\n",
    "\n",
    "modifTxt=txt\n",
    "txtIndex=0\n",
    "\n",
    "for i in range(len(txt)):\n",
    "\n",
    "    match=re.search(rePhrase, modifTxt[txtIndex:]) \n",
    "    \n",
    "    try:\n",
    "        matchTxt=match.group()[1:]\n",
    "    except:\n",
    "        break\n",
    "        \n",
    "\n",
    "    #calculate z-score\n",
    "    val,unit=matchTxt.split()\n",
    "    val=np.array([float(val)])\n",
    "    \n",
    "    if unit==\"Scm\":\n",
    "        val=np.log10(val)\n",
    "    \n",
    "    zval=scalingDict[unit].transform(val.reshape(1,-1))[0][0]\n",
    "    zval=round(zval, 5)\n",
    "    \n",
    "    #replace text\n",
    "    repText=str(zval)+ \" \" + unit\n",
    "    #print(match.group(),repText)\n",
    "\n",
    "    modifTxt=modifTxt[:match.start()+1+txtIndex]+repText+modifTxt[match.end()+txtIndex:]\n",
    "    txtIndex=txtIndex+match.start()+len(repText)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parsing by NLP and preparing graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split text by each ID\n",
    "IDList = re.findall('#ID(.+?)#comment', modifTxt)\n",
    "textList=re.findall('#text(.+?)#ID', modifTxt)\n",
    "\n",
    "#saving\n",
    "with open(\"textList.bin\", mode=\"wb\") as f:\n",
    "    joblib.dump(textList, f, compress=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utility funcs for processing...\n",
    "\n",
    "def is_num(s):\n",
    "    try:\n",
    "        float(s)\n",
    "    except ValueError:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "\n",
    "#make graphs from text\n",
    "def graphFromText(text,sentenceNum=0):\n",
    "    \n",
    "    #parsing\n",
    "    doc = nlp(text)\n",
    "    sentence=doc.sentences[sentenceNum]\n",
    "    dependencyArray=[[words.index,words.text,words.governor] for words in sentence.words]\n",
    "\n",
    "\n",
    "    idList,txtList,depList=list(zip(*dependencyArray))\n",
    "    idList=[\"node\"+str(i) for i in idList]\n",
    "    depList=[\"node\"+str(i) for i in depList]\n",
    "\n",
    "    edgeList=list(zip(idList,depList))\n",
    "\n",
    "\n",
    "    g=nx.Graph()\n",
    "    for edge in edgeList:\n",
    "        g.add_edge(edge[0],edge[1])\n",
    "\n",
    "    for ind,txt in zip(idList,txtList):\n",
    "        g.add_node(ind,label=txt)\n",
    "\n",
    "    g.add_node(\"node0\",label=\".\")\n",
    "    \n",
    "    return g\n",
    "\n",
    "\n",
    "#manually delete trivial nodes\n",
    "def deleteTrivialNodes(g):\n",
    "    delList=[\"at\",\"were\",\"and\",\",\",\".\",\n",
    "             \"was\",\"by\",\"to\",\"(\",\")\",\"an\",\n",
    "            \"which\",\"of\",\"a\",\"for\",\"in\",\"\\\"\",\n",
    "            ]\n",
    "\n",
    "    for nodeName in list(g.nodes):\n",
    "        if len(list(g.neighbors(nodeName)))==1:\n",
    "            nodeLabel=g.nodes[nodeName][\"label\"]\n",
    "            if nodeLabel in delList:\n",
    "                g.remove_node(nodeName)\n",
    "    return g\n",
    "\n",
    "#finalizing\n",
    "def finalizeProcessGraph(g):\n",
    "    #manually recover electricconductivity and Scm\n",
    "    for nodeName in list(g.nodes):\n",
    "        nodeLabel=g.nodes[nodeName][\"label\"]\n",
    "        if nodeLabel==\"electricconductivity\":\n",
    "            g.nodes[nodeName][\"label\"]=\"electric conductivity\"\n",
    "        elif nodeLabel==\"Scm\":\n",
    "            g.nodes[nodeName][\"label\"]=\"[S/cm]\"\n",
    "            \n",
    "    #compound node values: from 1234 to C_C1234\n",
    "    for nodeName in list(g.nodes):\n",
    "        nodeLabel=g.nodes[nodeName][\"label\"]\n",
    "        if re.search(\"C[0-9]{4}\", nodeLabel):\n",
    "            g.nodes[nodeName][\"label\"]=nodeLabel.replace(\"C\",\"C_C\")            \n",
    "    return g\n",
    "    \n",
    "#draw graph\n",
    "def drawGraph(g,drawLabel=True,printNodes=False):\n",
    "    pos = nx.spring_layout(g, k=0.1)\n",
    "    plt.figure(3,figsize=(30,30)) \n",
    "\n",
    "    if drawLabel:\n",
    "        gDict={}\n",
    "        for node in g.nodes:\n",
    "            gDict[node]=g.nodes[node][\"label\"]\n",
    "\n",
    "        plt.figure(1,figsize=(12,12)) \n",
    "        nx.draw(g,with_labels = True, alpha=0.8,labels=gDict,font_size=15,node_size=100) #NEW FUNCTION\n",
    "\n",
    "    else:\n",
    "        nx.draw(g,pos, with_labels = True)\n",
    "\n",
    "\n",
    "    if printNodes:\n",
    "         for node in g.nodes:\n",
    "            print(node,\"  \",g.nodes[node][\"label\"])       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download tokenizer data\n",
    "stanfordnlp.download('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init parser\n",
    "nlp = stanfordnlp.Pipeline(processors= \"tokenize,pos,depparse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text to graphs\n",
    "graphList=[]\n",
    "for text in tqdm(textList):\n",
    "    g=graphFromText(text,0)\n",
    "    g=deleteTrivialNodes(g)\n",
    "    g=finalizeProcessGraph(g)\n",
    "    graphList.append(g)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save\n",
    "with open(\"input/autoPEDOTPSS/PEDOT_PSS_autoprocessedGraph.graphbin\", mode=\"wb\") as f:\n",
    "    joblib.dump(graphList, f, compress=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check graphs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawGraph(graphList[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 ('chem')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "c589eb75a13cd6170a846e6cd0dfac133323f761785447705e97dd987e75c266"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
